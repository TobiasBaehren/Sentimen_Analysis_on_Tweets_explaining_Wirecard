{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a94c23-31f8-4934-ba01-1136ae84c6ce",
   "metadata": {},
   "source": [
    "<h1>Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd965f2-4a7b-4891-a7b0-223407654dc4",
   "metadata": {},
   "source": [
    "<h2>Import Libaries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a789995-a5c5-4f45-8b81-20c271b7af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.stats.diagnostic as dg\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab5679-d042-4784-aae7-1872c826ff38",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Laden der Datens√§tze</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3fa8ccf-34f9-4526-8d3f-f3ef2662eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/0dwb2f6j0f39f4r2j9yyjf180000gn/T/ipykernel_20909/2487132561.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_de[\"Week\"][each] = df_de[\"Week\"][each] + 1\n"
     ]
    }
   ],
   "source": [
    "#Load German Sentiment CSV file.\n",
    "df_de = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/Sentiment_Analysis/Dataset_DE_Bert_Vader.csv\", sep=\";\",\n",
    "                parse_dates=[\"created_at\"])\n",
    "\n",
    "#Change the date field\n",
    "df_de[\"Date\"] = pd.to_datetime(df_de.created_at).apply(lambda x: x.date())\n",
    "\n",
    "#Change the values of sentiment bert field and add a new field for a numeric value sentiment value \n",
    "df_de[\"sentiment_bert\"] = df_de[\"sentiment_bert\"].replace([\"neutral\", \"negative\", \"positive\"], [\"NEU\", \"NEG\", \"POS\"])\n",
    "df_de[\"sentiment_bert_value\"] = df_de[\"sentiment_bert\"].replace({\"NEU\": 0, \"NEG\": -1, \"POS\": 1})\n",
    "\n",
    "#Create a new field for a numeric sentiment value\n",
    "df_de[\"sentiment_vader_value\"] = [1 if i >= 0.05 else -1 if i <= -0.05 else 0 for i in df_de[\"sentiment_vader\"]]\n",
    "\n",
    "#Create a df for adding the year and week to the df\n",
    "df_de_week_year = pd.DataFrame([(i.isocalendar().week, i.isocalendar().year, i.isocalendar().weekday) for i in df_de[\"Date\"]],\n",
    "                               columns=[\"Week\", \"Year\", \"Weekday\"])\n",
    "\n",
    "#Recalulate the week\n",
    "for each in range(len(df_de_week_year)):\n",
    "    if ((df_de_week_year.iloc[each][\"Weekday\"] > 5) & (df_de_week_year.iloc[each][\"Week\"] != 1)):\n",
    "        df_de_week_year.iloc[each][\"Week\"] = df_de_week_year.iloc[each][\"Week\"] - 1\n",
    "    elif ((df_de_week_year.iloc[each][\"Weekday\"] > 5) & (df_de_week_year.iloc[each][\"Week\"] == 1)):\n",
    "        df_de_week_year.iloc[each][\"Week\"] = 52\n",
    "\n",
    "#Adding the week and year information to the df\n",
    "df_de[[\"Week\", \"Year\"]] = df_de_week_year[[\"Week\", \"Year\"]]\n",
    "\n",
    "tweet_id_friday_list = []\n",
    "for each in range(len(df_de)):\n",
    "    if (df_de[\"Date\"][each].isocalendar().year == 2016) & (df_de[\"Date\"][each].isocalendar().week == 12) & (df_de[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_de[\"Date\"][each].isocalendar().year == 2017) & (df_de[\"Date\"][each].isocalendar().week == 15) & (df_de[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_de[\"Date\"][each].isocalendar().year == 2018) & (df_de[\"Date\"][each].isocalendar().week == 13) & (df_de[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_de[\"Date\"][each].isocalendar().year == 2019) & (df_de[\"Date\"][each].isocalendar().week == 16) & (df_de[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_de[\"Date\"][each].isocalendar().year == 2020) & (df_de[\"Date\"][each].isocalendar().week == 15) & (df_de[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_de[\"Date\"][each].isocalendar().year == 2020) & (df_de[\"Date\"][each].isocalendar().week == 18) & (df_de[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "\n",
    "for each in tweet_id_friday_list:\n",
    "    df_de[\"Week\"][each] = df_de[\"Week\"][each] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467f3bf8-1a24-4956-a4bf-a3b094bd9d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/0dwb2f6j0f39f4r2j9yyjf180000gn/T/ipykernel_20909/1593085834.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en[\"Week\"][each] = df_en[\"Week\"][each] + 1\n"
     ]
    }
   ],
   "source": [
    "#Load English Sentiment CSV file.\n",
    "df_en = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/Sentiment_Analysis/Dataset_Bert_Vader.csv\", sep=\";\",\n",
    "                parse_dates=[\"created_at\"])\n",
    "\n",
    "#Change the date field\n",
    "df_en[\"Date\"] = pd.to_datetime(df_en.created_at).apply(lambda x: x.date())\n",
    "\n",
    "#Add a new column for a numeric sentiment bert value\n",
    "df_en[\"sentiment_bert_value\"] = df_en[\"sentiment_bert\"].replace({\"NEU\": 0, \"NEG\": -1, \"POS\": 1})\n",
    "\n",
    "#Add a new column for a numeric sentiment vader value\n",
    "df_en[\"sentiment_vader_value\"] = [1 if i >= 0.05 else -1 if i <= -0.05 else 0 for i in df_en[\"sentiment_vader\"]]\n",
    "\n",
    "#Create a df for adding the year and week to the df\n",
    "df_en_week_year = pd.DataFrame([(i.isocalendar().week, i.isocalendar().year, i.isocalendar().weekday) for i in df_en[\"Date\"]],\n",
    "                               columns=[\"Week\", \"Year\", \"Weekday\"])\n",
    "\n",
    "#Recalulate the week\n",
    "for each in range(len(df_en_week_year)):\n",
    "    if ((df_en_week_year.iloc[each][\"Weekday\"] > 5) & (df_en_week_year.iloc[each][\"Week\"] != 1)):\n",
    "        df_en_week_year.iloc[each][\"Week\"] = df_en_week_year.iloc[each][\"Week\"] - 1\n",
    "    elif ((df_en_week_year.iloc[each][\"Weekday\"] > 5) & (df_en_week_year.iloc[each][\"Week\"] == 1)):\n",
    "        df_en_week_year.iloc[each][\"Week\"] = 52\n",
    "        \n",
    "#Adding the week and year information to the df\n",
    "df_en[[\"Week\", \"Year\"]] = df_en_week_year[[\"Week\", \"Year\"]]\n",
    "        \n",
    "tweet_id_friday_list = []\n",
    "for each in range(len(df_en)):\n",
    "    if (df_en[\"Date\"][each].isocalendar().year == 2016) & (df_en[\"Date\"][each].isocalendar().week == 12) & (df_en[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_en[\"Date\"][each].isocalendar().year == 2017) & (df_en[\"Date\"][each].isocalendar().week == 15) & (df_en[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_en[\"Date\"][each].isocalendar().year == 2018) & (df_en[\"Date\"][each].isocalendar().week == 13) & (df_en[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_en[\"Date\"][each].isocalendar().year == 2019) & (df_en[\"Date\"][each].isocalendar().week == 16) & (df_en[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_en[\"Date\"][each].isocalendar().year == 2020) & (df_en[\"Date\"][each].isocalendar().week == 15) & (df_en[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "    elif (df_en[\"Date\"][each].isocalendar().year == 2020) & (df_en[\"Date\"][each].isocalendar().week == 18) & (df_en[\"Date\"][each].isocalendar().weekday == 5):\n",
    "        tweet_id_friday_list.append(each)\n",
    "\n",
    "for each in tweet_id_friday_list:\n",
    "    df_en[\"Week\"][each] = df_en[\"Week\"][each] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0488f3b9-17c3-4538-bec2-556c8f08b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the different DFs\n",
    "df = pd.concat([df_en, df_de]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc28569-0468-47df-995d-75c96e8ccbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the values from sentiment_bert_value from text to a num value\n",
    "df[\"sentiment_bert_value\"] = df[\"sentiment_bert\"].replace({\"NEU\": 0, \"NEG\": -1, \"POS\": 1})\n",
    "\n",
    "#Create a df for adding the year and week to the df\n",
    "df_week_year = pd.DataFrame([(i.isocalendar().week, i.isocalendar().year) for i in df[\"Date\"]], columns=[\"Week\", \"Year\"])\n",
    "#Adding the week and year information to the df\n",
    "df[[\"Week\", \"Year\"]] = df_week_year[[\"Week\", \"Year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0760bbd-5bfd-4c51-a97c-13caa01b8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Wirecard finance CSV file.\n",
    "df_wdi = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/WDI.HM-2.csv\", parse_dates=[\"Date\"])\n",
    "df_wdi = df_wdi.rename(columns={\"Adj Close\": \"Adj_Close\"})\n",
    "\n",
    "#Load Euro Stoxx 50 CSV file.\n",
    "df_stoxx = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/^STOXX50E.csv\", parse_dates=[\"Date\"])\n",
    "#df_stoxx = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/^GDAXI.csv\", parse_dates=[\"Date\"])\n",
    "df_stoxx = df_stoxx.rename(columns={\"Adj Close\": \"Adj_Close\"})\n",
    "\n",
    "#Load Visa finance CSV file.\n",
    "df_visa = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/V.csv\", parse_dates=[\"Date\"])\n",
    "df_visa = df_visa.rename(columns={\"Adj Close\": \"Adj_Close\"})\n",
    "\n",
    "#Load Master Card finance CSV file.\n",
    "df_ma = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/MA.csv\", parse_dates=[\"Date\"])\n",
    "df_ma = df_ma.rename(columns={\"Adj Close\": \"Adj_Close\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70381be5-4bda-46f8-9763-c6526fcd6bdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Data Preparation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b15ffe86-961d-4473-b6db-24f15de55f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Date f√ºr df_wdi & df\n",
    "df_wdi[\"Date\"] = pd.to_datetime(df_wdi.Date).apply(lambda x: x.date())\n",
    "df_stoxx[\"Date\"] = pd.to_datetime(df_stoxx.Date).apply(lambda x: x.date())\n",
    "df_visa[\"Date\"] = pd.to_datetime(df_visa.Date).apply(lambda x: x.date())\n",
    "df_ma[\"Date\"] = pd.to_datetime(df_ma.Date).apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d535620-9a68-4cff-bf54-469b89d3025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finance_df(df):\n",
    "    #Create df for returning\n",
    "    df_week = pd.DataFrame(columns=[\"Date\", \"Week\", \"Year\", \"Adj_Close\"])\n",
    "    \n",
    "    #Start Week\n",
    "    week = 5\n",
    "    volume = 0\n",
    "    \n",
    "    #To loop through all lines in df\n",
    "    for each in range(len(df)):\n",
    "        #Get the date\n",
    "        each_date = df[\"Date\"][each]\n",
    "        adj_close = df[\"Adj_Close\"][each]\n",
    "        \n",
    "        #Get the Volume of all transactions in a week\n",
    "        volume = volume + df[\"Volume\"][each]\n",
    "\n",
    "        #Check if the date is the last date\n",
    "        if df[\"Date\"][each] == datetime.date(2020,7,31):\n",
    "            #Get Week Number, start and end day\n",
    "            week = each_date.isocalendar().week\n",
    "            year = each_date.isocalendar().year\n",
    "            end_day = df[\"Date\"].iloc[-1]\n",
    "            \n",
    "            #Add data to df\n",
    "            new_row = pd.DataFrame([[each_date, week, year, adj_close, volume]],\n",
    "                                   columns=[\"Date\", \"Week\", \"Year\", \"Adj_Close\", \"Volume\"])\n",
    "            df_week = pd.concat([df_week, new_row], ignore_index=True)\n",
    "        else:\n",
    "            #Get the next week number for checking\n",
    "            next_week = df[\"Date\"][each+1].isocalendar().week\n",
    "\n",
    "            #Check if the next day is in another week \n",
    "            if each_date.isocalendar().week != next_week:\n",
    "                #Get week number, year and last date\n",
    "                week = each_date.isocalendar().week\n",
    "                year = each_date.isocalendar().year\n",
    "                end_day = each_date\n",
    "                \n",
    "                #Add data to df\n",
    "                new_row = pd.DataFrame([[each_date, week, year, adj_close, volume]],\n",
    "                                       columns=[\"Date\", \"Week\", \"Year\", \"Adj_Close\", \"Volume\"])\n",
    "                df_week = pd.concat([df_week, new_row], ignore_index=True)\n",
    "                \n",
    "                #Set Volume back to 0\n",
    "                volume = 0\n",
    "    \n",
    "    #Add the yield from one week to another\n",
    "    df_week[\"returns_week\"] = df_week.Adj_Close.pct_change()+1\n",
    "    #df_week[\"returns_week\"] = np.log(df_week.Adj_Close.pct_change()+1)\n",
    "    #df_week[\"returns_week\"] = df_week.Adj_Close.pct_change()\n",
    "    #df_week[\"returns_week_log\"] = pd.Series(np.log(np.float64(df_week.Adj_Close))).pct_change()\n",
    "    \n",
    "\n",
    "    \n",
    "    #Return the new DF\n",
    "    return df_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac684914-0476-4759-9eb9-ebab0db5a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_finance_df(df_wdi = df_wdi, df_stoxx = df_stoxx, df_ma = df_ma, df_v = df_visa):\n",
    "    \n",
    "    #Create week dfs for all financial dfs\n",
    "    df_wdi_week = create_finance_df(df_wdi)\n",
    "    df_stoxx_week = create_finance_df(df_stoxx)\n",
    "    df_ma_week = create_finance_df(df_ma)\n",
    "    df_v_week = create_finance_df(df_v)\n",
    "    \n",
    "    #combine all dfs\n",
    "    df_week = pd.concat([df_wdi_week, df_stoxx_week.rename(columns={\"returns_week\": \"returns_stoxx\"})[\"returns_stoxx\"]],\n",
    "                        axis=1)\n",
    "    df_week = pd.concat([df_week, df_ma_week.rename(columns={\"returns_week\": \"returns_ma\"})[\"returns_ma\"]], axis=1)\n",
    "    df_week = pd.concat([df_week, df_v_week.rename(columns={\"returns_week\": \"returns_visa\"})[\"returns_visa\"]], axis=1)\n",
    "    return df_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "554f92ff-fb42-4dfc-85ac-7bc480f4e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_df(df_week, df, meta_data = False):\n",
    "    \n",
    "    #If meta data like Retweets should be used, this will calculate it.\n",
    "    if meta_data:\n",
    "        df[\"sentiment_bert_value\"] = df[\"sentiment_bert_value\"] * ((df[\"retweet_count\"] + 1))\n",
    "        df[\"sentiment_vader_value\"] = df[\"sentiment_vader_value\"] * ((df[\"retweet_count\"] + 1))\n",
    "    \n",
    "    df_sum_year_week_bert = pd.DataFrame(df[[\"Week\", \"Year\", \"sentiment_bert_value\"]].\n",
    "                                    groupby(by=[\"Year\", \"Week\"]).sum()).reset_index()\n",
    "\n",
    "    df_sum_year_week_vader = pd.DataFrame(df[[\"Week\", \"Year\", \"sentiment_vader_value\"]].\n",
    "                                    groupby(by=[\"Year\", \"Week\"]).sum()).reset_index()\n",
    "    \n",
    "    df_count_tweets_year_week = pd.DataFrame(df[[\"Week\", \"Year\", \"conversation_id\"]].\n",
    "                                    groupby(by=[\"Year\", \"Week\"]).\n",
    "             count()).reset_index().rename(columns={\"conversation_id\": \"count_all_tweets\"})\n",
    "    \n",
    "    df_week = df_week.merge(df_sum_year_week_bert)\n",
    "    df_week = df_week.merge(df_sum_year_week_vader)\n",
    "    df_week = df_week.merge(df_count_tweets_year_week)\n",
    "    \n",
    "    return df_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ffd6b2-7ea6-4425-ae32-548027fd5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(df_twitter = df.copy()):\n",
    "    df_week = concat_finance_df()\n",
    "    df_week_reg = create_final_df(df_week, df_twitter)\n",
    "    \n",
    "    df_week_reg[\"dif_sentiment_bert_value\"] = df_week_reg[\"sentiment_bert_value\"].diff()\n",
    "    df_week_reg[\"dif_sentiment_vader_value\"] = df_week_reg[\"sentiment_vader_value\"].diff()\n",
    "\n",
    "    df_week_reg.dropna(inplace=True)\n",
    "    df_week_reg = df_week_reg.reset_index(drop=True)\n",
    "\n",
    "    return df_week_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54fa90-d4d3-40be-af28-ba4cd9d961c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Linear Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f32f94f5-bae5-416d-809f-397e81eadfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(df, regressor, output):\n",
    "    \n",
    "    x = df[regressor]\n",
    "    y = df[output]\n",
    "    \n",
    "    x = sm.add_constant(x)\n",
    "\n",
    "    model = sm.OLS(y,x).fit()\n",
    "    \n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    pritn_model = model.summary()\n",
    "    \n",
    "    print(pritn_model)\n",
    "    \n",
    "    return predictions, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29518455-fd3f-46f3-a9e4-39cada3d4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WLS_regression(df, regressor, output, weiter):\n",
    "    \n",
    "    x = df[regressor]\n",
    "    y = df[output]\n",
    "    \n",
    "    x = sm.add_constant(x)\n",
    "\n",
    "    model = sm.WLS(y,x, weiter).fit()\n",
    "    \n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    pritn_model = model.summary()\n",
    "    \n",
    "    print(pritn_model)\n",
    "    \n",
    "    return predictions, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20748c4c-f48d-4a8d-aaef-ae695a8e33b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Execute</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49abf430-8bcc-4a24-8d52-4cdb309e1869",
   "metadata": {},
   "source": [
    "<p>Multiple Lineare Regression der deutschen Tweets mit BERT</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e450930-ab8f-4382-b65d-1051ab43c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           returns_week   R-squared:                       0.727\n",
      "Model:                            OLS   Adj. R-squared:                  0.720\n",
      "Method:                 Least Squares   F-statistic:                     100.8\n",
      "Date:                Wed, 07 Dec 2022   Prob (F-statistic):           3.55e-61\n",
      "Time:                        22:03:44   Log-Likelihood:                 290.96\n",
      "No. Observations:                 234   AIC:                            -567.9\n",
      "Df Residuals:                     227   BIC:                            -543.7\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        0.1017      0.187      0.545      0.586      -0.266       0.469\n",
      "dif_sentiment_bert_value     0.0004   3.43e-05     10.710      0.000       0.000       0.000\n",
      "returns_stoxx                0.4573      0.203      2.257      0.025       0.058       0.856\n",
      "returns_ma                   0.1289      0.323      0.400      0.690      -0.507       0.765\n",
      "returns_visa                 0.3245      0.389      0.833      0.406      -0.443       1.092\n",
      "Volume                    2.943e-07    3.5e-07      0.841      0.401   -3.95e-07    9.84e-07\n",
      "count_all_tweets         -3.037e-05    1.1e-05     -2.760      0.006   -5.21e-05   -8.69e-06\n",
      "==============================================================================\n",
      "Omnibus:                      101.334   Durbin-Watson:                   2.303\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1057.741\n",
      "Skew:                           1.383   Prob(JB):                    2.06e-230\n",
      "Kurtosis:                      13.042   Cond. No.                     4.40e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regressor = [\"dif_sentiment_bert_value\", \"returns_stoxx\", \"returns_ma\", \"returns_visa\", \"Volume\", \"count_all_tweets\"]\n",
    "\n",
    "regressand = [\"returns_week\"]\n",
    "\n",
    "df_week_reg = create_df(df_de)\n",
    "\n",
    "reg_predictions, reg_model = regression(df_week_reg, regressor, regressand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ceb03fdc-6fb9-4cd8-a025-7f2e4fab291b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                       5.863983e-01\n",
       "dif_sentiment_bert_value    6.241022e-22\n",
       "returns_stoxx               2.493319e-02\n",
       "returns_ma                  6.897633e-01\n",
       "returns_visa                4.056692e-01\n",
       "Volume                      4.010908e-01\n",
       "count_all_tweets            6.248443e-03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7f77a262-2351-47e8-8fa1-4713a19ac1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/statsmodels/stats/diagnostic.py:1081: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  aug = res.fittedvalues[:, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4288902152711113e-23"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset = dg.linear_reset(reg_model, power=3, test_type=\"fitted\", use_f=True)\n",
    "reset.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294f333-355f-423a-a35c-20a453925efd",
   "metadata": {},
   "source": [
    "<p>________________________________________________________________________________</p>\n",
    "<p>Multiple lineare Regression in deutsch mit VADER</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2ac0206d-d364-4e35-8e92-3d215133b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           returns_week   R-squared:                       0.632\n",
      "Model:                            OLS   Adj. R-squared:                  0.622\n",
      "Method:                 Least Squares   F-statistic:                     64.93\n",
      "Date:                Wed, 07 Dec 2022   Prob (F-statistic):           1.49e-46\n",
      "Time:                        22:04:14   Log-Likelihood:                 255.97\n",
      "No. Observations:                 234   AIC:                            -497.9\n",
      "Df Residuals:                     227   BIC:                            -473.7\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.0145      0.217      0.067      0.947      -0.413       0.442\n",
      "dif_sentiment_vader_value     0.0004    7.8e-05      5.136      0.000       0.000       0.001\n",
      "returns_stoxx                 0.6066      0.236      2.567      0.011       0.141       1.072\n",
      "returns_ma                    0.4057      0.374      1.086      0.279      -0.330       1.142\n",
      "returns_visa                 -0.0009      0.452     -0.002      0.998      -0.891       0.889\n",
      "Volume                     3.361e-06   2.27e-07     14.809      0.000    2.91e-06    3.81e-06\n",
      "count_all_tweets             -0.0001   7.19e-06    -17.051      0.000      -0.000      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                       82.942   Durbin-Watson:                   1.875\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1067.092\n",
      "Skew:                           0.973   Prob(JB):                    1.92e-232\n",
      "Kurtosis:                      13.279   Cond. No.                     4.39e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.39e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regressor = [\"dif_sentiment_vader_value\", \"returns_stoxx\", \"returns_ma\", \"returns_visa\", \"Volume\", \"count_all_tweets\"]\n",
    "\n",
    "regressand = [\"returns_week\"]\n",
    "\n",
    "df_week_reg = create_df(df_de)\n",
    "\n",
    "reg_predictions, reg_model = regression(df_week_reg, regressor, regressand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "be7675c2-6c29-4748-8d42-e3c23fee5da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                        9.468218e-01\n",
       "dif_sentiment_vader_value    6.043831e-07\n",
       "returns_stoxx                1.089218e-02\n",
       "returns_ma                   2.786104e-01\n",
       "returns_visa                 9.983902e-01\n",
       "Volume                       3.566145e-35\n",
       "count_all_tweets             1.597010e-42\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69d57ffb-19ce-4924-8112-c7a8fedbc237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/statsmodels/stats/diagnostic.py:1081: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  aug = res.fittedvalues[:, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8191544307145805e-37"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset = dg.linear_reset(reg_model, power=3, test_type=\"fitted\", use_f=True)\n",
    "reset.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f1455-9970-4612-a745-976b313899b0",
   "metadata": {},
   "source": [
    "<p>________________________________________________________________________________</p>\n",
    "<p>Multiple lineare Regression mit BERT auf englischen Tweets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "adcf6da2-5945-4504-aff1-1aef459150aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           returns_week   R-squared:                       0.700\n",
      "Model:                            OLS   Adj. R-squared:                  0.692\n",
      "Method:                 Least Squares   F-statistic:                     88.24\n",
      "Date:                Wed, 07 Dec 2022   Prob (F-statistic):           1.52e-56\n",
      "Time:                        22:05:28   Log-Likelihood:                 279.89\n",
      "No. Observations:                 234   AIC:                            -545.8\n",
      "Df Residuals:                     227   BIC:                            -521.6\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        0.0727      0.196      0.372      0.711      -0.313       0.458\n",
      "dif_sentiment_bert_value     0.0001   2.03e-05      6.401      0.000    8.99e-05       0.000\n",
      "returns_stoxx                0.5251      0.213      2.468      0.014       0.106       0.944\n",
      "returns_ma                   0.1027      0.338      0.304      0.762      -0.563       0.769\n",
      "returns_visa                 0.3069      0.408      0.753      0.452      -0.496       1.110\n",
      "Volume                    1.343e-06   5.36e-07      2.506      0.013    2.87e-07     2.4e-06\n",
      "count_all_tweets         -4.436e-05   1.29e-05     -3.426      0.001   -6.99e-05   -1.88e-05\n",
      "==============================================================================\n",
      "Omnibus:                       59.283   Durbin-Watson:                   2.188\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              549.046\n",
      "Skew:                          -0.652   Prob(JB):                    5.97e-120\n",
      "Kurtosis:                      10.390   Cond. No.                     4.40e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regressor = [\"dif_sentiment_bert_value\", \"returns_stoxx\", \"returns_ma\", \"returns_visa\", \"Volume\", \"count_all_tweets\"]\n",
    "\n",
    "regressand = [\"returns_week\"]\n",
    "\n",
    "df_week_reg = create_df(df_en)\n",
    "\n",
    "reg_predictions, reg_model = regression(df_week_reg, regressor, regressand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffe21752-33e2-46f5-906f-697607d6b5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                       7.105238e-01\n",
       "dif_sentiment_bert_value    8.725965e-10\n",
       "returns_stoxx               1.431993e-02\n",
       "returns_ma                  7.615167e-01\n",
       "returns_visa                4.523541e-01\n",
       "Volume                      1.291670e-02\n",
       "count_all_tweets            7.274211e-04\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4188f5e3-f600-454e-a0e7-2bc761cfb829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/statsmodels/stats/diagnostic.py:1081: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  aug = res.fittedvalues[:, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.125824428392394e-24"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset = dg.linear_reset(reg_model, power=3, test_type=\"fitted\", use_f=True)\n",
    "reset.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9c15a-99f7-4956-85cd-c0098058ccbc",
   "metadata": {},
   "source": [
    "<p>________________________________________________________________________________</p>\n",
    "<p>Multiple lineare Regression mit VADER auf englische Tweets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b514721b-3913-4742-a24a-66263f876c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           returns_week   R-squared:                       0.726\n",
      "Model:                            OLS   Adj. R-squared:                  0.719\n",
      "Method:                 Least Squares   F-statistic:                     100.2\n",
      "Date:                Wed, 07 Dec 2022   Prob (F-statistic):           5.54e-61\n",
      "Time:                        22:05:33   Log-Likelihood:                 290.50\n",
      "No. Observations:                 234   AIC:                            -567.0\n",
      "Df Residuals:                     227   BIC:                            -542.8\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1700      0.187      0.907      0.365      -0.199       0.539\n",
      "dif_sentiment_vader_value     0.0002   2.76e-05      8.149      0.000       0.000       0.000\n",
      "returns_stoxx                 0.4409      0.204      2.162      0.032       0.039       0.843\n",
      "returns_ma                    0.1883      0.323      0.582      0.561      -0.449       0.825\n",
      "returns_visa                  0.2051      0.390      0.526      0.599      -0.563       0.973\n",
      "Volume                     2.927e-07   5.55e-07      0.528      0.598      -8e-07    1.39e-06\n",
      "count_all_tweets          -1.569e-05   1.38e-05     -1.140      0.256   -4.28e-05    1.14e-05\n",
      "==============================================================================\n",
      "Omnibus:                       71.242   Durbin-Watson:                   2.333\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              388.066\n",
      "Skew:                          -1.067   Prob(JB):                     5.40e-85\n",
      "Kurtosis:                       8.937   Cond. No.                     4.40e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regressor = [\"dif_sentiment_vader_value\", \"returns_stoxx\", \"returns_ma\", \"returns_visa\", \"Volume\", \"count_all_tweets\"]\n",
    "\n",
    "regressand = [\"returns_week\"]\n",
    "\n",
    "df_week_reg = create_df(df_en)\n",
    "\n",
    "reg_predictions, reg_model = regression(df_week_reg, regressor, regressand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b0b31544-e285-44cb-9758-00d25ee52950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                        3.653728e-01\n",
       "dif_sentiment_vader_value    2.458160e-14\n",
       "returns_stoxx                3.165560e-02\n",
       "returns_ma                   5.609230e-01\n",
       "returns_visa                 5.991945e-01\n",
       "Volume                       5.982656e-01\n",
       "count_all_tweets             2.556760e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6a68b437-2876-4e2f-8495-7c72870448e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/statsmodels/stats/diagnostic.py:1081: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  aug = res.fittedvalues[:, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.631405841830008e-20"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset = dg.linear_reset(reg_model, power=3, test_type=\"fitted\", use_f=True)\n",
    "reset.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9550ec-099f-4128-85ab-59a5c8e5206f",
   "metadata": {},
   "source": [
    "<p>________________________________________________________________________________</p>\n",
    "<p>Multiple lineare Regression mit BERT auf alle Tweets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "728234bb-9be3-4982-b585-42228890df6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           returns_week   R-squared:                       0.765\n",
      "Model:                            OLS   Adj. R-squared:                  0.759\n",
      "Method:                 Least Squares   F-statistic:                     123.1\n",
      "Date:                Wed, 07 Dec 2022   Prob (F-statistic):           1.73e-68\n",
      "Time:                        22:05:53   Log-Likelihood:                 308.42\n",
      "No. Observations:                 234   AIC:                            -602.8\n",
      "Df Residuals:                     227   BIC:                            -578.7\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        0.0110      0.173      0.063      0.949      -0.330       0.352\n",
      "dif_sentiment_bert_value  8.887e-05   8.89e-06      9.996      0.000    7.14e-05       0.000\n",
      "returns_stoxx                0.5698      0.188      3.030      0.003       0.199       0.940\n",
      "returns_ma                   0.1492      0.299      0.499      0.618      -0.440       0.738\n",
      "returns_visa                 0.2769      0.361      0.767      0.444      -0.434       0.988\n",
      "Volume                    9.545e-07   3.93e-07      2.426      0.016    1.79e-07    1.73e-06\n",
      "count_all_tweets         -1.733e-05   5.31e-06     -3.262      0.001   -2.78e-05   -6.86e-06\n",
      "==============================================================================\n",
      "Omnibus:                      103.607   Durbin-Watson:                   2.149\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              884.666\n",
      "Skew:                          -1.500   Prob(JB):                    7.89e-193\n",
      "Kurtosis:                      12.041   Cond. No.                     4.40e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regressor = [\"dif_sentiment_bert_value\", \"returns_stoxx\", \"returns_ma\", \"returns_visa\", \"Volume\", \"count_all_tweets\"]\n",
    "\n",
    "regressand = [\"returns_week\"]\n",
    "\n",
    "df_week_reg = create_df()\n",
    "\n",
    "reg_predictions, reg_model = regression(df_week_reg, regressor, regressand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c3cfd9ca-cec1-4f78-9f77-74c02f1438e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                       9.494638e-01\n",
       "dif_sentiment_bert_value    9.919889e-20\n",
       "returns_stoxx               2.729299e-03\n",
       "returns_ma                  6.182534e-01\n",
       "returns_visa                4.437239e-01\n",
       "Volume                      1.605783e-02\n",
       "count_all_tweets            1.276459e-03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb71ebe3-df4d-46ac-b466-47de014c161b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/statsmodels/stats/diagnostic.py:1081: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  aug = res.fittedvalues[:, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7712849938118904e-15"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset = dg.linear_reset(reg_model, power=3, test_type=\"fitted\", use_f=True)\n",
    "reset.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e8c338-d24d-4e06-9d69-4007a0e5da4e",
   "metadata": {},
   "source": [
    "<p>________________________________________________________________________________</p>\n",
    "<p>Multiple lineare Regression mit VADER auf alle Tweets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9f72fa35-5629-4a22-ae1a-fb1f8c3448cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           returns_week   R-squared:                       0.718\n",
      "Model:                            OLS   Adj. R-squared:                  0.711\n",
      "Method:                 Least Squares   F-statistic:                     96.38\n",
      "Date:                Wed, 07 Dec 2022   Prob (F-statistic):           1.31e-59\n",
      "Time:                        22:06:10   Log-Likelihood:                 287.21\n",
      "No. Observations:                 234   AIC:                            -560.4\n",
      "Df Residuals:                     227   BIC:                            -536.2\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.0471      0.190      0.248      0.804      -0.326       0.421\n",
      "dif_sentiment_vader_value     0.0001   1.98e-05      6.762      0.000     9.5e-05       0.000\n",
      "returns_stoxx                 0.5497      0.206      2.670      0.008       0.144       0.955\n",
      "returns_ma                    0.2212      0.327      0.676      0.500      -0.423       0.866\n",
      "returns_visa                  0.1892      0.395      0.479      0.632      -0.589       0.968\n",
      "Volume                     1.599e-06    4.6e-07      3.479      0.001    6.93e-07    2.51e-06\n",
      "count_all_tweets           -2.44e-05   6.46e-06     -3.778      0.000   -3.71e-05   -1.17e-05\n",
      "==============================================================================\n",
      "Omnibus:                      106.116   Durbin-Watson:                   2.325\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              752.744\n",
      "Skew:                          -1.619   Prob(JB):                    3.50e-164\n",
      "Kurtosis:                      11.168   Cond. No.                     4.40e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regressor = [\"dif_sentiment_vader_value\", \"returns_stoxx\", \"returns_ma\", \"returns_visa\", \"Volume\", \"count_all_tweets\"]\n",
    "\n",
    "regressand = [\"returns_week\"]\n",
    "\n",
    "df_week_reg = create_df()\n",
    "\n",
    "reg_predictions, reg_model = regression(df_week_reg, regressor, regressand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "14418ec6-0088-4d72-a551-6d1c5209e675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                        8.040902e-01\n",
       "dif_sentiment_vader_value    1.140359e-10\n",
       "returns_stoxx                8.142642e-03\n",
       "returns_ma                   4.995541e-01\n",
       "returns_visa                 6.324005e-01\n",
       "Volume                       6.032766e-04\n",
       "count_all_tweets             2.022125e-04\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "45b5f055-5ce8-44d9-a223-ea5aed7c09dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/statsmodels/stats/diagnostic.py:1081: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  aug = res.fittedvalues[:, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.165383251524327e-26"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset = dg.linear_reset(reg_model, power=3, test_type=\"fitted\", use_f=True)\n",
    "reset.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a347e-e028-4907-a02b-0701904acbf5",
   "metadata": {},
   "source": [
    "<p>________________________________________________________________________________</p>\n",
    "<p>Grundanalyse</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b726292-b2db-4299-98a6-d8ca8a1f4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = [\"dif_sentiment_bert_value\", \"returns_stoxx\", \"returns_ma\", \"returns_visa\", \"Volume\", \"count_all_tweets\"]\n",
    "regressor = [\"dif_sentiment_vader_value\", \"returns_stoxx\", \"returns_ma\", \"returns_visa\", \"Volume\", \"count_all_tweets\"]\n",
    "\n",
    "regressand = [\"returns_week\"]\n",
    "\n",
    "df_week_reg = create_df()\n",
    "\n",
    "reg_predictions, reg_model = regression(df_week_reg, regressor, regressand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5b6736e-72e5-4072-b542-428cc4c62a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 66.219162\n",
      "p 0.0\n"
     ]
    }
   ],
   "source": [
    "reset = dg.linear_reset(reg_model, power=3, test_type=\"fitted\", use_f=True)\n",
    "print(\"F\", np.round(reset.fvalue, 6))\n",
    "print(\"p\", np.round(reset.pvalue, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "81fcea02-8030-4b01-bbc1-ab0000ddd788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/statsmodels/stats/diagnostic.py:1081: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  aug = res.fittedvalues[:, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.165383251524327e-26"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset = dg.linear_reset(reg_model, power=3, test_type=\"fitted\", use_f=True)\n",
    "reset.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a80803-b51b-40d4-9a31-613cc4a702cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d810de4-c27e-4678-aaa1-1c09e1fff811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_3.9.10",
   "language": "python",
   "name": "master_thesis_3.9.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
