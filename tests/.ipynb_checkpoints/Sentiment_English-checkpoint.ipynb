{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c47f4a-8c4e-477b-8206-2c8bc3d0c570",
   "metadata": {},
   "source": [
    "<h1>Sentiment Analyse Englisch</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e953e42-f7c3-4bbd-b1df-4ddd0666d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import datetime\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "import torch\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869c13c6-5451-48d0-89a3-58312d21bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edce1f1c-f60a-45ce-becc-0c5b242cbcf9",
   "metadata": {},
   "source": [
    "<p>Laden des Datensatzes</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15d4ae5f-d7f0-4fa8-af1d-c2d5509d4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/Final_EN/Dataset_Wirecard.csv\", sep=\";\",\n",
    "                 parse_dates=[\"created_at\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680db78-5153-43a8-a4ae-3b85d6f03300",
   "metadata": {},
   "source": [
    "<h2>BERTweet</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "adb07c75-ebf7-45d3-b3a4-1487c1dd9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate emojis\n",
    "def remove_duplicate_emoji(orig_str):\n",
    "    prev_emoji = None\n",
    "    remove_duplicate_emoji = []\n",
    "    for c in orig_str:\n",
    "        if c in emoji.EMOJI_DATA:\n",
    "            if prev_emoji == c:\n",
    "                continue\n",
    "            prev_emoji = c\n",
    "        remove_duplicate_emoji.append(c)\n",
    "    return \"\".join(remove_duplicate_emoji)\n",
    "\n",
    "#remove all emojis\n",
    "def de_emojify(text):\n",
    "    regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" \n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regex_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e9c93746-0400-407c-9438-59a932f2c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2faae7fa-4402-41a3-9ac8-16d246d1d2f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37400\n",
      "Add\n",
      "NEU\n",
      "37401\n",
      "Add\n",
      "37401 NEU\n",
      "37402\n",
      "Add\n",
      "NEU\n",
      "37403\n",
      "Add\n",
      "NEU\n",
      "37404\n",
      "Add\n",
      "NEG\n"
     ]
    }
   ],
   "source": [
    "#Zum Testen\n",
    "for each in range(37400,37405):\n",
    "    print(each)\n",
    "    try:\n",
    "        if len(emoji.demojize(df.iloc[each][\"text\"])) >= 425:\n",
    "            print(each, \" in if 1\")\n",
    "            if len(emoji.demojize(remove_duplicate_emoji(df.iloc[each][\"text\"]))) >= 425:\n",
    "                print(each, \" in if 2\")\n",
    "                if len(de_emojify(df.iloc[each][\"text\"])) >= 425:\n",
    "                    print(each, \" in if 3\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Add ohne Emojis\")\n",
    "                    print(classifier(de_emojify(df.iloc[each][\"text\"]))[0][\"label\"])\n",
    "            else:\n",
    "                print(\"Add ohne doppelte Emojis\")\n",
    "                print(classifier(emoji.demojize(remove_duplicate_emoji(df.iloc[each][\"text\"])))[0][\"label\"])\n",
    "        else:\n",
    "            print(\"Add\")\n",
    "            print(classifier(emoji.demojize(df.iloc[each][\"text\"]))[0][\"label\"])\n",
    "    except Exception:\n",
    "        print(each, \"NEU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "5dc635a7-40f1-4616-a95a-a7e90eb73f0e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37401\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n",
      "50000\n",
      "50500\n",
      "51000\n",
      "51500\n",
      "52000\n",
      "52500\n",
      "53000\n",
      "53500\n",
      "54000\n",
      "54500\n",
      "55000\n",
      "55500\n",
      "56000\n",
      "56500\n",
      "57000\n",
      "57500\n",
      "58000\n",
      "58500\n",
      "59000\n",
      "59500\n",
      "60000\n",
      "60500\n",
      "61000\n",
      "61500\n",
      "62000\n",
      "62500\n",
      "63000\n",
      "63500\n",
      "64000\n",
      "64500\n",
      "65000\n",
      "65500\n",
      "65723\n",
      "66000\n",
      "66500\n",
      "67000\n",
      "67500\n",
      "68000\n",
      "68500\n",
      "69000\n",
      "69500\n",
      "70000\n",
      "70500\n",
      "71000\n",
      "71500\n",
      "72000\n",
      "72500\n",
      "73000\n",
      "73500\n",
      "74000\n",
      "74500\n",
      "75000\n",
      "75500\n",
      "76000\n",
      "76500\n",
      "77000\n",
      "77500\n",
      "78000\n",
      "78500\n",
      "79000\n",
      "79500\n",
      "80000\n",
      "80500\n",
      "81000\n",
      "81500\n",
      "82000\n",
      "82500\n",
      "83000\n",
      "83500\n",
      "84000\n",
      "84500\n",
      "85000\n",
      "85500\n",
      "86000\n",
      "86500\n",
      "87000\n",
      "87500\n",
      "88000\n",
      "88500\n",
      "89000\n",
      "89500\n",
      "90000\n",
      "90500\n",
      "91000\n",
      "91500\n",
      "92000\n",
      "92500\n",
      "93000\n",
      "93500\n",
      "94000\n",
      "94500\n",
      "95000\n",
      "95500\n",
      "96000\n",
      "96500\n",
      "97000\n",
      "97500\n",
      "98000\n",
      "98500\n",
      "99000\n",
      "99465\n",
      "99500\n",
      "100000\n",
      "100500\n",
      "101000\n",
      "101500\n",
      "102000\n",
      "102500\n",
      "103000\n",
      "103500\n",
      "104000\n",
      "104500\n",
      "105000\n",
      "105500\n",
      "106000\n",
      "106500\n",
      "107000\n",
      "107500\n",
      "108000\n",
      "108500\n",
      "109000\n",
      "109500\n",
      "110000\n",
      "110500\n",
      "111000\n"
     ]
    }
   ],
   "source": [
    "#Produktiv\n",
    "list_sentiment_bert = []\n",
    "list_error_tweets = []\n",
    "n = 500\n",
    "for each in range(len(df)):\n",
    "    if (each/n) == 1:\n",
    "        print(each)\n",
    "        n = n + 500\n",
    "    try:\n",
    "        if len(emoji.demojize(df.iloc[each][\"text\"])) >= 425:\n",
    "            if len(emoji.demojize(remove_duplicate_emoji(df.iloc[each][\"text\"]))) >= 425:\n",
    "                if len(de_emojify(df.iloc[each][\"text\"])) >= 425:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_sentiment_bert.append(classifier(de_emojify(df.iloc[each][\"text\"]))[0][\"label\"])\n",
    "            else:\n",
    "                list_sentiment_bert.append(classifier(emoji.demojize(remove_duplicate_emoji(df.iloc[each][\"text\"])))[0][\"label\"])\n",
    "        else:\n",
    "            list_sentiment_bert.append(classifier(emoji.demojize(df.iloc[each][\"text\"]))[0][\"label\"])\n",
    "    except Exception:\n",
    "        print(each)\n",
    "        list_sentiment_bert.append(\"NEU\")\n",
    "        list_error_tweets.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "95cfe8e0-be8d-4a9f-9279-79a02a17e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111199\n",
      "111199\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(list_sentiment_bert))\n",
    "print(len(list_error_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "7073cd63-e02f-465e-94cb-671db3ceb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_backup = list_sentiment_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6133537e-49b2-4fb0-ba99-e540757e546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in list_error_tweets:\n",
    "    list_sentiment_bert[each] = classifier(re.sub('[#|$|=|(|)|&|\\r]', '', df.iloc[each][\"text\"]))[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "dba70584-5fb4-4a5f-8087-e8b670f9f240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37401\n",
      "NEU\n",
      "65723\n",
      "NEU\n",
      "99465\n",
      "NEG\n"
     ]
    }
   ],
   "source": [
    "for each in list_error_tweets:\n",
    "    print(each)\n",
    "    print(list_sentiment_bert[each])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "943b8b1e-faed-4ae2-b0ae-9646e75d2c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU OPEN: Indices: Slightly softer. Eurostoxx 50 -0.2%Sectors: Health care leads, IT lagsMovers: ASM +7%, Carrefour +4%, Bayer +3%,  Wirecard +2.2%, UBS +1.8%, Michelin +1.8%, Nokia -10%, Sainsbury's -4.2%, Peugeot -2.4%, RBS -1.5%, CBK -1.1%, Barcs -1% \n",
      "\n",
      "252 \n",
      "\n",
      "[{'label': 'NEU', 'score': 0.9029528498649597}] \n",
      "\n",
      "NEU \n",
      "\n",
      " Update:  Back on Friday, June 12th, 2020, Mr. Sayyid Imrani, Customer Service Manager 610 420-4824 [ sayyid.imrani ] from Wirecard contacted \n",
      "\n",
      "141 \n",
      "\n",
      "[{'label': 'NEU', 'score': 0.9708991050720215}] \n",
      "\n",
      "NEU \n",
      "\n",
      "WayFair-gt;Snopes-gt;Wirecard-gt;at Jack-gt;MSM Media-gt;1% CIA-gt;Soros-gt;House of Saud-gt;â€˜FEDâ€™ Central Bank-gt;Roths-gt;Hollywood-gt;Jeffrey Epstein Island-gt;George Floyd-gt;Kobe Bryant-gt;Aliens Exist-gt;HRC-gt;Blrock 1-gt;Slush-gt;Alice in Wonderland-gt;WikiLeaks-gt;Mass Ext. Events-gt;QAnon \n",
      "\n",
      "299 \n",
      "\n",
      "[{'label': 'NEG', 'score': 0.9800840616226196}] \n",
      "\n",
      "NEG \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each in list_error_tweets:\n",
    "    print(re.sub('[#|$|=|(|)|&|\\r]', '', df.iloc[each][\"text\"]), \"\\n\")\n",
    "    print(len(re.sub('[#|$|=|(|)|&|\\r]', '', df.iloc[each][\"text\"])), \"\\n\")\n",
    "    print(classifier(re.sub('[#|$|=|(|)|&|\\r]', '', df.iloc[each][\"text\"])), \"\\n\")\n",
    "    print(classifier(re.sub('[#|$|=|(|)|&|\\r]', '', df.iloc[each][\"text\"]))[0][\"label\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "3db30ce2-9ecd-4f8e-b63a-090d46b42b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_bert\"] = list_sentiment_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f1ab83c0-0317-475f-900a-b8964ed4d280",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>referenced_tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703142204341026818</td>\n",
       "      <td>349287204</td>\n",
       "      <td>2016-02-26 08:58:59+00:00</td>\n",
       "      <td>703142204341026818</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1/2 I see Wirecard is rebounding after CEO Mar...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>695255175334924288</td>\n",
       "      <td>428593285</td>\n",
       "      <td>2016-02-04 14:38:45+00:00</td>\n",
       "      <td>695255175334924288</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Thank you for following us Markus Braun!</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>695237701386244098</td>\n",
       "      <td>95129352</td>\n",
       "      <td>2016-02-04 13:29:19+00:00</td>\n",
       "      <td>695237701386244098</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Disrupt the Banks! (Jeff Stewart, Markus Braun...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>718385114170966016</td>\n",
       "      <td>17616154</td>\n",
       "      <td>2016-04-08 10:28:52+00:00</td>\n",
       "      <td>718385114170966016</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WDI wirecard CEO Markus Braun on Q4 2015 Resul...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>718384477215567873</td>\n",
       "      <td>546713</td>\n",
       "      <td>2016-04-08 10:26:20+00:00</td>\n",
       "      <td>718384477215567873</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Wirecard Analyst Call transcript is available ...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      conversation_id  author_id                created_at  \\\n",
       "0  703142204341026818  349287204 2016-02-26 08:58:59+00:00   \n",
       "1  695255175334924288  428593285 2016-02-04 14:38:45+00:00   \n",
       "2  695237701386244098   95129352 2016-02-04 13:29:19+00:00   \n",
       "3  718385114170966016   17616154 2016-04-08 10:28:52+00:00   \n",
       "4  718384477215567873     546713 2016-04-08 10:26:20+00:00   \n",
       "\n",
       "             tweet_id lang  retweet_count  reply_count  like_count  \\\n",
       "0  703142204341026818   en              0            0           1   \n",
       "1  695255175334924288   en              0            0           0   \n",
       "2  695237701386244098   en              1            0           1   \n",
       "3  718385114170966016   en              0            0           0   \n",
       "4  718384477215567873   en              1            0           3   \n",
       "\n",
       "   quote_count              source tweet_type referenced_tweet_id  \\\n",
       "0            0  Twitter Web Client       None                None   \n",
       "1            0               IFTTT       None                None   \n",
       "2            0  Twitter Web Client       None                None   \n",
       "3            0  Twitter Web Client       None                None   \n",
       "4            0  Twitter Web Client       None                None   \n",
       "\n",
       "                                                text sentiment_bert  \n",
       "0  1/2 I see Wirecard is rebounding after CEO Mar...            NEU  \n",
       "1           Thank you for following us Markus Braun!            POS  \n",
       "2  Disrupt the Banks! (Jeff Stewart, Markus Braun...            NEG  \n",
       "3  WDI wirecard CEO Markus Braun on Q4 2015 Resul...            NEU  \n",
       "4  Wirecard Analyst Call transcript is available ...            NEU  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "7a869542-6c2a-47d1-86a3-e413ad2331bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dataset_Bert.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf8b3a-5618-454b-a20e-1bc5a1c054cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de.to_csv('Dataset_Wirecard.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b81a314f-d857-4d9d-982c-8d707c4e4964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das  ist ein Test Text\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Das = ist (ein) #Test Text\"\n",
    "print(re.sub('[#|$|=|(|)|&|\\r]', '', test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b460fcc7-f902-48f3-820f-fe00876a353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEU', 'NEU', 'POS', 'NEU', 'NEG', 'NEU', 'NEU']\n",
      "['NEU', 'Test', 'POS', 'NEU', 'NEG', 'NEU', 'NEU']\n"
     ]
    }
   ],
   "source": [
    "list_test = [\"NEU\", \"NEU\", \"POS\", \"NEU\", \"NEG\", \"NEU\", \"NEU\"]\n",
    "print(list_test)\n",
    "list_test[1] = \"Test\"\n",
    "print(list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0787e0-44ae-4e30-bb53-3116f5296c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "42ac9c98-bf88-476b-bb79-df32ed9558d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEU\n",
      "NEU\n",
      "NEU\n"
     ]
    }
   ],
   "source": [
    "for each in list_error_tweets:\n",
    "    print(list_sentiment_bert[each])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2d35e453-5c3c-4d10-bcfc-f0ddaa978b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEU\n"
     ]
    }
   ],
   "source": [
    "print(list_sentiment_bert[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb03365-9d0b-428e-ace9-49f674da560d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af6da2-7bbd-4852-b943-3d1aba8b3bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "72b6a5d0-ea93-4b7a-8ee5-8c697a78d658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEU\n",
      "37401 : NEU\n",
      "NEU\n",
      "NEU\n",
      "NEG\n"
     ]
    }
   ],
   "source": [
    "list_error = []\n",
    "for each in range(37400,37405):\n",
    "    try:\n",
    "        print(classifier(df.iloc[each][\"text\"])[0][\"label\"])\n",
    "    except Exception:\n",
    "        print(each, \": NEU\")\n",
    "        list_error.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "07c8e677-2919-4584-9837-5b43fade55fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37401]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d72a5-013e-4f91-b44a-5e4148ab767d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d8a56a9b-49e8-42b9-9b0a-24bef663d3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.9387667775154114}]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(emoji.demojize(remove_duplicate_emoji(df.iloc[4008][\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "3896feaa-acbd-4dde-a8e9-8a327da60dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emoji.demojize(remove_duplicate_emoji(df.iloc[4008][\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "eb4d683e-1b37-4537-9bd8-a6a09526a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_long_tweets = []\n",
    "for each in range(len(df)):\n",
    "    if len(emoji.demojize(df.iloc[each][\"text\"])) >= 420:\n",
    "        list_long_tweets.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4751a81f-e4eb-4dad-9b1a-4f692c09f491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_long_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "05b48b39-6bdd-4f66-bdaf-87099be3a758",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "Keine Emojis:  [{'label': 'POS', 'score': 0.5555543303489685}] \n",
      "\n",
      "4008\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.8998799324035645}] \n",
      "\n",
      "4571\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.6770298480987549}] \n",
      "\n",
      "23303\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.6649094223976135}] \n",
      "\n",
      "25369\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.869737446308136}] \n",
      "\n",
      "48073\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.9201696515083313}] \n",
      "\n",
      "54573\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.7760960459709167}] \n",
      "\n",
      "54575\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.9476966261863708}] \n",
      "\n",
      "54750\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.5990377068519592}] \n",
      "\n",
      "70445\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.9204390645027161}] \n",
      "\n",
      "72517\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.9812843203544617}] \n",
      "\n",
      "73958\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.9808570146560669}] \n",
      "\n",
      "76133\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.9633225798606873}] \n",
      "\n",
      "76623\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.9772890210151672}] \n",
      "\n",
      "77157\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.9633225798606873}] \n",
      "\n",
      "79340\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.9853197932243347}] \n",
      "\n",
      "79537\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.7647624611854553}] \n",
      "\n",
      "79874\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.9853197932243347}] \n",
      "\n",
      "80682\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.9846937656402588}] \n",
      "\n",
      "92051\n",
      "Keine Emojis:  [{'label': 'NEG', 'score': 0.6326236724853516}] \n",
      "\n",
      "93210\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.7760960459709167}] \n",
      "\n",
      "93212\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.9476966261863708}] \n",
      "\n",
      "93387\n",
      "Keine Emojis:  [{'label': 'POS', 'score': 0.86567223072052}] \n",
      "\n",
      "101051\n",
      "Keine Emojis:  [{'label': 'POS', 'score': 0.5633422136306763}] \n",
      "\n",
      "109293\n",
      "Keine Emojis:  [{'label': 'NEU', 'score': 0.8986361026763916}] \n",
      "\n",
      "109892\n",
      "[{'label': 'NEU', 'score': 0.939254105091095}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each in list_long_tweets:\n",
    "    print(each)\n",
    "    if len(remove_duplicate_emoji(emoji.demojize(df.iloc[each][\"text\"]))) > 425:\n",
    "        print(\"Keine Emojis: \", classifier(de_emojify(df.iloc[each][\"text\"])), \"\\n\")\n",
    "    else:\n",
    "        print(classifier(remove_duplicate_emoji(emoji.demojize(df.iloc[each][\"text\"]))), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a28d5ece-8b57-4950-ac24-d24b38834c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emoji.demojize(df.iloc[4008][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235a338-c79c-4916-baa4-bbf477dc0e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298eceb-38ba-428c-aae1-079b762113b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(list_sentiment_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5a00855d-23c1-42c7-90da-47d3c069f65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEU', 'NEU', 'NEU', 'POS', 'NEG', 'NEU', 'NEG', 'NEU', 'POS', 'NEU']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sentiment_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "60b23cb0-0a40-4117-bea2-465736334592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_sentiment_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8013ad9d-f0d8-47e3-9e13-3722fb42802d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "81498f72-06c6-406e-addc-5f6a2bbbc518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_sentiment_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9e6130c8-d911-4014-a173-7b7fe8f31ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in list_sentiment_vader:\n",
    "    print(len(each), \": \", each, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a376fa-65da-4ec5-96fc-bae2b2453250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ðŸ’¯ðŸ‘‰AskCar Travel &amp; Rentals Ent.ðŸ‘ˆðŸ’¯CAR RENTALS &amp; CHAUFFEUR SERVICESðŸš˜â†ªMERCEDES S400hâ†©ðŸš˜ðŸš˜â†ªBMW 730Li &amp; 740Li â†©ðŸš˜âœ”âœ”FREE DELIVERY &amp; PICK UP ðŸš¢ðŸš¢âœ”âœ”BRAND NEW MODELS ðŸš—ðŸš—âœ”âœ”WITH OR WITHOUT DRIVER ðŸ‘®ðŸ‘®âœ”âœ”ESCORT &amp; BODYGUARD ðŸ’‚ðŸ’‚ðŸ“ž+60109315786 CALL / WhatsAppðŸ“ž  \n",
      "\n",
      " ðŸ’¥ðŸ‘‡DO NEVER EVER TRUST UNDER-ATTACK COMPANIES' &amp; MNGT PRESS RELEASESðŸ‘‡ðŸ’¥ðŸ‘‡just bulls**tðŸ‘‡WDI Wirecard  ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡ðŸ‘‡  \n",
      "\n",
      " ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚SoftBank needs to start looking at its other investments . It needs to ask uber where itâ€™s been keeping its money .ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[153][\"text\"], \"\\n\\n\", df.iloc[80682][\"text\"], \"\\n\\n\", df.iloc[109293][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe1b11-b469-456e-99cb-970f0333aa45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b8b494e7-910b-456c-9f19-57a938d797b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'emoji' has no attribute 'UNICODE_EMOJI_ENGLISH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [160]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mremove_duplicate_emoji\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m153\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [157]\u001b[0m, in \u001b[0;36mremove_duplicate_emoji\u001b[0;34m(orig_str)\u001b[0m\n\u001b[1;32m      3\u001b[0m remove_duplicate_emoji \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m orig_str:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43memoji\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUNICODE_EMOJI_ENGLISH\u001b[49m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m prev_emoji \u001b[38;5;241m==\u001b[39m c:\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'emoji' has no attribute 'UNICODE_EMOJI_ENGLISH'"
     ]
    }
   ],
   "source": [
    "remove_duplicate_emoji(df.iloc[153][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f8e7c542-2bf4-4b00-ad83-2e6680d79aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_emoji(orig_str):\n",
    "    prev_emoji = None\n",
    "    remove_duplicate_emoji = []\n",
    "    for c in orig_str:\n",
    "        if c in emoji.UNICODE_EMOJI_ENGLISH:\n",
    "            if prev_emoji == c:\n",
    "                continue\n",
    "            prev_emoji = c\n",
    "        remove_duplicate_emoji.append(c)\n",
    "    return \"\".join(remove_duplicate_emoji)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7a11e7d-4775-42ef-b198-f65fd25ea656",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ðŸ’¯ðŸ‘‰AskCar Travel &amp; Rentals Ent.ðŸ‘ˆðŸ’¯CAR RENTALS &amp; CHAUFFEUR SERVICESðŸš˜â†ªMERCEDES S400hâ†©ðŸš˜ðŸš˜â†ªBMW 730Li &amp; 740Li â†©ðŸš˜âœ”âœ”FREE DELIVERY &amp; PICK UP ðŸš¢ðŸš¢âœ”âœ”BRAND NEW MODELS ðŸš—ðŸš—âœ”âœ”WITH OR WITHOUT DRIVER ðŸ‘®ðŸ‘®âœ”âœ”ESCORT &amp; BODYGUARD ðŸ’‚ðŸ’‚ðŸ“ž+60109315786 CALL / WhatsAppðŸ“ž  \n",
      "\n",
      " :hundred_points::backhand_index_pointing_right:AskCar Travel &amp; Rentals Ent.:backhand_index_pointing_left::hundred_points:CAR RENTALS &amp; CHAUFFEUR SERVICES:oncoming_automobile::left_arrow_curving_right:MERCEDES S400h:right_arrow_curving_left::oncoming_automobile::oncoming_automobile::left_arrow_curving_right:BMW 730Li &amp; 740Li :right_arrow_curving_left::oncoming_automobile::check_mark::check_mark:FREE DELIVERY &amp; PICK UP :ship::ship::check_mark::check_mark:BRAND NEW MODELS :automobile::automobile::check_mark::check_mark:WITH OR WITHOUT DRIVER :police_officer::police_officer::check_mark::check_mark:ESCORT &amp; BODYGUARD :guard::guard::telephone_receiver:+60109315786 CALL / WhatsApp:telephone_receiver:  \n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(emoji\u001b[38;5;241m.\u001b[39mdemojize(df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43memoji\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdemojize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(classifier(emoji\u001b[38;5;241m.\u001b[39mdemojize(df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:125\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        If `self.return_all_scores=True`, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;66;03m# This pipeline is odd, and return a list when single item is run\u001b[39;00m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [result]\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1026\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1033\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1032\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1033\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:943\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m    942\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 943\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:137\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1209\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1209\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1220\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1221\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:844\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    842\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 844\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    852\u001b[0m     embedding_output,\n\u001b[1;32m    853\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    862\u001b[0m )\n\u001b[1;32m    863\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:137\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    135\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 137\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     embeddings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m    139\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "i = 153\n",
    "\n",
    "print(df.iloc[i][\"text\"], \"\\n\")\n",
    "\n",
    "print(emoji.demojize(df.iloc[i][\"text\"]), \"\\n\")\n",
    "\n",
    "print(classifier(emoji.demojize(df.iloc[i][\"text\"])), \"\\n\")\n",
    "\n",
    "print(classifier(emoji.demojize(df.iloc[i][\"text\"]))[0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d7c380a8-2b1b-4b2c-b350-e75a2d37a19c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m :hundred_points::backhand_index_pointing_right:AskCar Travel &amp; Rentals Ent.:backhand_index_pointing_left::hundred_points:CAR RENTALS &amp; CHAUFFEUR SERVICES:oncoming_automobile::left_arrow_curving_right:MERCEDES S400h:right_arrow_curving_left::oncoming_automobile::oncoming_automobile::left_arrow_curving_right:BMW 730Li &amp; 740Li :right_arrow_curving_left::oncoming_automobile::check_mark::check_mark:FREE DELIVERY &amp; PICK UP :ship::ship::check_mark::check_mark:BRAND NEW MODELS :automobile:...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:125\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        If `self.return_all_scores=True`, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;66;03m# This pipeline is odd, and return a list when single item is run\u001b[39;00m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [result]\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1026\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1033\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1032\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1033\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:943\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m    942\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 943\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:137\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1209\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1209\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1220\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1221\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:844\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    842\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 844\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    852\u001b[0m     embedding_output,\n\u001b[1;32m    853\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    862\u001b[0m )\n\u001b[1;32m    863\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:137\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    135\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 137\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     embeddings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m    139\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/torch/nn/functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "classifier(\" :hundred_points::backhand_index_pointing_right:AskCar Travel &amp; Rentals Ent.:backhand_index_pointing_left::hundred_points:CAR RENTALS &amp; CHAUFFEUR SERVICES:oncoming_automobile::left_arrow_curving_right:MERCEDES S400h:right_arrow_curving_left::oncoming_automobile::oncoming_automobile::left_arrow_curving_right:BMW 730Li &amp; 740Li :right_arrow_curving_left::oncoming_automobile::check_mark::check_mark:FREE DELIVERY &amp; PICK UP :ship::ship::check_mark::check_mark:BRAND NEW MODELS :automobile:...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2d2cc3ef-26f4-4d92-a368-f705336810a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" :hundred_points::backhand_index_pointing_right:AskCar Travel &amp; Rentals Ent.:backhand_index_pointing_left::hundred_points:CAR RENTALS &amp; CHAUFFEUR SERVICES:oncoming_automobile::left_arrow_curving_right:MERCEDES S400h:right_arrow_curving_left::oncoming_automobile::oncoming_automobile::left_arrow_curving_right:BMW 730Li &amp; 740Li :right_arrow_curving_left::oncoming_automobile::check_mark::check_mark:FREE DELIVERY &amp; PICK UP :ship::ship::check_mark::check_mark:BRAND NEW MODELS :automobile:...\"\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "09987af4-9fe0-4c1d-b26d-fb544480b3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.8941224813461304}]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"this is a new text and I need to try to reach more than 503 characters to see if this is the limit of the classifier function. This would mean, I need to rethink the process how I can go through all the tweets. Normally, this should not be an issue only if someone is entereing so many emojis... I need more then 100 characters more, I do not know what I can write anymore. I am just a bit pissed, that this is not working as easy as expected... I am almost there, and I think I am close to be done with it:\"\n",
    "print(len(text))\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4479610-74d5-4696-a293-b6eb8f45e08c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>referenced_tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703142204341026818</td>\n",
       "      <td>349287204</td>\n",
       "      <td>2016-02-26 08:58:59+00:00</td>\n",
       "      <td>703142204341026818</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1/2 I see Wirecard is rebounding after CEO Mar...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>695255175334924288</td>\n",
       "      <td>428593285</td>\n",
       "      <td>2016-02-04 14:38:45+00:00</td>\n",
       "      <td>695255175334924288</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Thank you for following us Markus Braun!</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>695237701386244098</td>\n",
       "      <td>95129352</td>\n",
       "      <td>2016-02-04 13:29:19+00:00</td>\n",
       "      <td>695237701386244098</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Disrupt the Banks! (Jeff Stewart, Markus Braun...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>718385114170966016</td>\n",
       "      <td>17616154</td>\n",
       "      <td>2016-04-08 10:28:52+00:00</td>\n",
       "      <td>718385114170966016</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WDI wirecard CEO Markus Braun on Q4 2015 Resul...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>718384477215567873</td>\n",
       "      <td>546713</td>\n",
       "      <td>2016-04-08 10:26:20+00:00</td>\n",
       "      <td>718384477215567873</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Wirecard Analyst Call transcript is available ...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      conversation_id  author_id                created_at  \\\n",
       "0  703142204341026818  349287204 2016-02-26 08:58:59+00:00   \n",
       "1  695255175334924288  428593285 2016-02-04 14:38:45+00:00   \n",
       "2  695237701386244098   95129352 2016-02-04 13:29:19+00:00   \n",
       "3  718385114170966016   17616154 2016-04-08 10:28:52+00:00   \n",
       "4  718384477215567873     546713 2016-04-08 10:26:20+00:00   \n",
       "\n",
       "             tweet_id lang  retweet_count  reply_count  like_count  \\\n",
       "0  703142204341026818   en              0            0           1   \n",
       "1  695255175334924288   en              0            0           0   \n",
       "2  695237701386244098   en              1            0           1   \n",
       "3  718385114170966016   en              0            0           0   \n",
       "4  718384477215567873   en              1            0           3   \n",
       "\n",
       "   quote_count              source tweet_type referenced_tweet_id  \\\n",
       "0            0  Twitter Web Client       None                None   \n",
       "1            0               IFTTT       None                None   \n",
       "2            0  Twitter Web Client       None                None   \n",
       "3            0  Twitter Web Client       None                None   \n",
       "4            0  Twitter Web Client       None                None   \n",
       "\n",
       "                                                text sentiment_vader  \n",
       "0  1/2 I see Wirecard is rebounding after CEO Mar...             NEU  \n",
       "1           Thank you for following us Markus Braun!             NEU  \n",
       "2  Disrupt the Banks! (Jeff Stewart, Markus Braun...             NEU  \n",
       "3  WDI wirecard CEO Markus Braun on Q4 2015 Resul...             NEU  \n",
       "4  Wirecard Analyst Call transcript is available ...             NEU  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5974c0-8048-4c8e-9e46-e24bb5e88fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_emojis = []\n",
    "list_emoji_name = []\n",
    "list_emoji_sentiment = []\n",
    "for each in range(len(df)):\n",
    "    tweet_text = df.iloc[each][\"text\"]\n",
    "    for emoticon in emoji.emoji_lis(tweet_text):\n",
    "        if emoticon[\"emoji\"] not in list_emojis:\n",
    "            list_emojis.append(emoticon[\"emoji\"])\n",
    "\n",
    "df_emoji = pd.DataFrame(list_emojis)\n",
    "df_emoji.rename(columns={0: \"emoji\"}, inplace=True)\n",
    "\n",
    "for each in list_emojis:\n",
    "    list_emoji_name.append(emoji.demojize(each))\n",
    "\n",
    "df_emoji[\"shortcodes\"] = list_emoji_name\n",
    "    \n",
    "for each in list_emoji_name:\n",
    "    list_emoji_sentiment.append(classifier(each)[0][\"label\"])\n",
    "    \n",
    "df_emoji[\"sentiment\"] = list_emoji_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381649b-5d51-42d2-a780-204e65d91e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emoji.loc[df_emoji[\"sentiment\"] == \"NEU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640295c4-1b81-4b44-bd89-9937ca3f8c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ef2f259-2458-44b1-9164-a81cbeb0a549",
   "metadata": {},
   "source": [
    "<h2>Deutsch</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d2abbd-2fa4-4926-9d57-6abc445de8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"oliverguhr/german-sentiment-bert\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda95db7-6318-4ee8-9075-d5ac4a97332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/Final_DE/Dataset_Wirecard.csv\", sep=\";\",\n",
    "                 parse_dates=[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83daf0d9-254b-45cb-ac5d-dad9ffd7c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_emojis = []\n",
    "list_emoji_name = []\n",
    "list_emoji_sentiment = []\n",
    "for each in range(len(df)):\n",
    "    tweet_text = df.iloc[each][\"text\"]\n",
    "    for emoticon in emoji.emoji_list(tweet_text):\n",
    "        if emoticon[\"emoji\"] not in list_emojis:\n",
    "            list_emojis.append(emoticon[\"emoji\"])\n",
    "\n",
    "df_emoji = pd.DataFrame(list_emojis)\n",
    "df_emoji.rename(columns={0: \"emoji\"}, inplace=True)\n",
    "\n",
    "for each in list_emojis:\n",
    "    list_emoji_name.append(emoji.demojize(each, language=\"de\"))\n",
    "\n",
    "df_emoji[\"shortcodes\"] = list_emoji_name\n",
    "    \n",
    "for each in list_emoji_name:\n",
    "    list_emoji_sentiment.append(classifier(each)[0][\"label\"])\n",
    "    \n",
    "df_emoji[\"sentiment\"] = list_emoji_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c6cffa-4df3-4cf9-9649-c45bf2af6d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>shortcodes</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ðŸ“ˆ</td>\n",
       "      <td>:aufwÃ¤rtstrend:</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>â–¶</td>\n",
       "      <td>:wiedergabe:</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ðŸ˜</td>\n",
       "      <td>:sÃ¼ffisant_lÃ¤chelndes_gesicht:</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ðŸ˜‰</td>\n",
       "      <td>:zwinkerndes_gesicht:</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ¥‚</td>\n",
       "      <td>:sektglÃ¤ser:</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji                      shortcodes sentiment\n",
       "0     ðŸ“ˆ                 :aufwÃ¤rtstrend:  negative\n",
       "1     â–¶                    :wiedergabe:  negative\n",
       "2     ðŸ˜  :sÃ¼ffisant_lÃ¤chelndes_gesicht:  positive\n",
       "3     ðŸ˜‰           :zwinkerndes_gesicht:   neutral\n",
       "4     ðŸ¥‚                    :sektglÃ¤ser:  negative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emoji.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be574d-248c-4794-a5c5-adbe2da0b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji.demojize(\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06f42b5-2348-42ca-854a-97fb2325655b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python ist :daumen_hoch:'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.demojize('Python ist ðŸ‘', language=\"de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd7d3a-d647-419c-83b1-244cc0271c9a",
   "metadata": {},
   "source": [
    "<h1>Weitere Befehle</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7cfc81-4fb5-4217-860b-26ef717fe223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818eddef-c4dc-4759-ba6b-aca50f2ab380",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "for each in range(len(df)):\n",
    "    text_list.append(df.iloc[each][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9576e-3fa0-4604-9c08-78d4512902ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba9b9a-6cb9-409f-9e81-1e7ab5ebef81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for text in text_list:\n",
    "#    scores = sid.polarity_scores(text)\n",
    "#    print(scores['compound'], text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5ad5c-77a6-45b3-a1d4-27272187477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"look forward to one of our spotlight speaker markus braun, ceo of   drop by!\"\n",
    "for each in text.split():\n",
    "    #print(each)\n",
    "    if each in sid.lexicon:\n",
    "        print(each, sid.lexicon[each])\n",
    "sid.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd22f3a-d683-4e9d-adb3-73a9fc63c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid.lexicon[\"drop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc0ba9-6fe3-430c-b129-ec0dbf196af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_3.9.10",
   "language": "python",
   "name": "master_thesis_3.9.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
