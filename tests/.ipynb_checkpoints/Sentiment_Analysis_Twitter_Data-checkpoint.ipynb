{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "793b32d5-d676-4e7a-94c1-0fc413ecd124",
   "metadata": {},
   "source": [
    "<h1>Sentimentanalyse der Twitter Daten</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc0f4c-369b-4327-9a31-d93e94a4d7d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Aufgaben</h2>\n",
    "<p>Laden der Daten - DONE -</p>\n",
    "<p>Wie kann ich VADER nutzen um eine Sentimentanalyse durchzuführen</p>\n",
    "<p>Zusammenführen der Daten</p>\n",
    "<p>Aussortieren nicht benötigter Tweets und Daten</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee30e583-f0f5-481a-b934-6009505578e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "#If not downloaded:\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import flair\n",
    "import datetime\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a425c-a7fd-4360-9078-4ead8ee4f00f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Sentiment Test</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273f0b3-217e-459d-aaf9-359edcaf0c01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h3>VADER</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc01c1-84de-4943-b04b-3c560d7adf74",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p>Der versuche eine einfache Sentimentanalyse mit VADER anhand von Beispieldaten durchzuführen</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1527e99c-990f-4ffb-951f-9589c001f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969fc78e-695d-463b-be33-86e4ee9989f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of product reviews\n",
    "\n",
    "product_reviews = [\n",
    "    'I love this product. It helps me get so much work done. I tell everyone about what a great thing it is.',\n",
    "    'This product is defective. I feel like it is broken because it does not do what it promises. Do not buy this.',\n",
    "    'Do yourself a favor and buy this product as soon as possible. I recommend it to everyone I know. It has saved me so much time!',\n",
    "    'This product is overpriced and useless. It was a waste of money and it made all my hair fall out.',\n",
    "    'Works like a dream and it is a bargain! It solves my problems with ease. I bought two!',\n",
    "    'Do not buy! This product is a ripoff. I wish it was better, but it fails constantly. What a mistake!',\n",
    "    'This thing is garbage. Do yourself a favor and save the money. Mine is a dumpster fire and fell apart.',\n",
    "    'I adore this product. =) It makes my life so much easier. And it is a deal!'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c152b-4fff-40ac-87c3-fba05b2c81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each review in our `product_reviews` list\n",
    "# Store a polarity score in `scores`\n",
    "# Then print the score followed by the review\n",
    "for review in product_reviews:\n",
    "    scores = sid.polarity_scores(review)\n",
    "    print(scores['compound'], review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986b319-a36b-44a5-8aaf-ba39c6ed2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This thing is garbage Do yourself a favor and save the money Mine is a dumpster fire and fell apart\"\n",
    "for each in text.split():\n",
    "    if each in sid.lexicon:\n",
    "        print(each, sid.lexicon[each])\n",
    "sid.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1313d-d34b-4e5a-93a2-68ac3b82dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sid.polarity_scores(\"This is good\"))\n",
    "print(sid.polarity_scores(\"This is Good\"))\n",
    "print(sid.polarity_scores(\"This is GOOD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3cb34-244b-42f5-a7fa-6c8b17f1f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "like = \"I like this\"\n",
    "dont_like = \"I do not like this\"\n",
    "print(sid.polarity_scores(like))\n",
    "print(sid.polarity_scores(dont_like))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad1ce6-b565-47d1-8d91-e49f36f0503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "like = \"I like this!\"\n",
    "dont_like = \"I do not like this!\"\n",
    "print(sid.polarity_scores(like))\n",
    "print(sid.polarity_scores(dont_like))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c34070-a3c4-4b62-a43e-d78d34d904c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "like = \"I LIKE this\"\n",
    "dont_like = \"I do not LIKE this\"\n",
    "print(sid.polarity_scores(like))\n",
    "print(sid.polarity_scores(dont_like))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4010e-3732-465d-8ba9-789d947c6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "like = \"I LIKE this\"\n",
    "dont_like = \"I do NOT like this\"\n",
    "print(sid.polarity_scores(like))\n",
    "print(sid.polarity_scores(dont_like))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d1d0a-cb99-422f-ac61-dd12ce6694e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "like = \"I like this\"\n",
    "dont_like = \"I do NOT LIKE this\"\n",
    "print(sid.polarity_scores(like))\n",
    "print(sid.polarity_scores(dont_like))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b63ce-a523-4997-bb3c-ba6a2f409aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "notbad = \"not bad\"\n",
    "sid.polarity_scores(notbad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2874449-5b34-4b23-98b3-b1b759049cc3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h3>Flair</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdac25-6306-40f6-b67c-b53d01e5f2c5",
   "metadata": {},
   "source": [
    "<p>I try to use the flair framework to do a sentiment analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7e6c02-ba46-4807-bb08-c14c6f0bc379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 14:21:42,426 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-distilbert/sentiment-en-mix-distillbert_4.pt not found in cache, downloading to /var/folders/3r/0dwb2f6j0f39f4r2j9yyjf180000gn/T/tmpavddo4z8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 265512723/265512723 [02:49<00:00, 1565352.79B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 14:24:32,419 copying /var/folders/3r/0dwb2f6j0f39f4r2j9yyjf180000gn/T/tmpavddo4z8 to cache at /Users/tobias/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 14:24:32,525 removing temp file /var/folders/3r/0dwb2f6j0f39f4r2j9yyjf180000gn/T/tmpavddo4z8\n",
      "2022-03-24 14:24:32,536 loading file /Users/tobias/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654cbae2240e46c8ad520bdf2650682b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ba8bdcd49d41fea16713c27eade4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb98c0dc4534775a7c24f9c137631e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69636ac3c0834cd0b54de485b80f5027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flair_sentiment = flair.models.TextClassifier.load(\"en-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c9f90f-6594-4736-8fc2-4732f5568061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti_score(n):\n",
    "    s = flair.data.Sentence(n)\n",
    "    flair_sentiment.predict(s)\n",
    "    total_sentiment = s.labels[0]\n",
    "    assert total_sentiment.value in ['POSITIVE', 'NEGATIVE']\n",
    "    sign = 1 if total_sentiment.value == 'POSITIVE' else -1\n",
    "    score = total_sentiment.score\n",
    "    return sign * score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47a960b4-08e6-484e-b4d5-16d191bcecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"Tesla is a great company\"\n",
    "s2 = \"Tesla is a good company\"\n",
    "s3 = \"Tesla is just a company\"\n",
    "s4 = \"Tesla is a bad company\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "638264d4-9bdc-41e7-9b4f-67873553b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9977720379829407\n",
      "0.9961444139480591\n",
      "-0.8988595008850098\n",
      "-0.9998192191123962\n"
     ]
    }
   ],
   "source": [
    "print(senti_score(s1))\n",
    "print(senti_score(s2))\n",
    "print(senti_score(s3))\n",
    "print(senti_score(s4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "649d9344-77da-488d-b6d2-7eedaf7b8ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'compound': 0.6249}\n",
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.538, 'neu': 0.462, 'pos': 0.0, 'compound': -0.5423}\n"
     ]
    }
   ],
   "source": [
    "print(sid.polarity_scores(s1))\n",
    "print(sid.polarity_scores(s2))\n",
    "print(sid.polarity_scores(s3))\n",
    "print(sid.polarity_scores(s4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6473401f-c101-4e0a-82f9-92a48b984f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 15:04:39,506 https://nlp.informatik.hu-berlin.de/resources/models/de-offensive-language/germ-eval-2018-task-1-v0.8.pt not found in cache, downloading to /var/folders/3r/0dwb2f6j0f39f4r2j9yyjf180000gn/T/tmpge1ck4wu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 439837065/439837065 [03:57<00:00, 1848690.56B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 15:08:37,638 copying /var/folders/3r/0dwb2f6j0f39f4r2j9yyjf180000gn/T/tmpge1ck4wu to cache at /Users/tobias/.flair/models/germ-eval-2018-task-1-v0.8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 15:08:38,076 removing temp file /var/folders/3r/0dwb2f6j0f39f4r2j9yyjf180000gn/T/tmpge1ck4wu\n",
      "2022-03-24 15:08:38,096 loading file /Users/tobias/.flair/models/germ-eval-2018-task-1-v0.8.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a75e8c756cc4aba90c105e672aa536c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/83.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9be2bcc22742d188304e1336a9efe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/234k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e8e299e65f4fc9b460810839e6c792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/362 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flair_sentiment_all = flair.models.TextClassifier.load(\"de-offensive-language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d70acde-34b1-4b39-9c8f-c0fbd4ef3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = \"Tesla ist eine großartige Firma\"\n",
    "ds2 = \"Tesla ist eine tolle Firma\"\n",
    "ds3 = \"Tesla ist eine Firma\"\n",
    "ds4 = \"Tesla ist eine böse Firma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "917456c0-c061-47a1-aa1f-f18c6e232afc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mflair_sentiment_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/flair/nn/model.py:569\u001b[0m, in \u001b[0;36mDefaultClassifier.predict\u001b[0;34m(self, sentences, mini_batch_size, return_probabilities_for_all_classes, verbose, label_name, return_loss, embedding_storage_mode)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch:\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m scores, gold_labels, data_points, label_candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mreturn_label_candidates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;66;03m# remove previously predicted labels of this type\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m data_points:\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/flair/models/text_classification_model.py:60\u001b[0m, in \u001b[0;36mTextClassifier.forward_pass\u001b[0;34m(self, sentences, return_label_candidates)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_pass\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     55\u001b[0m                  sentences: Union[List[DataPoint], DataPoint],\n\u001b[1;32m     56\u001b[0m                  return_label_candidates: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m                  ):\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# embed sentences\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# make tensor for all embedded sentences in batch\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     embedding_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocument_embeddings\u001b[38;5;241m.\u001b[39mget_names()\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/flair/embeddings/base.py:55\u001b[0m, in \u001b[0;36mEmbeddings.embed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43msentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embeddings\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     56\u001b[0m             everything_embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_embeddings'"
     ]
    }
   ],
   "source": [
    "flair_sentiment_all.predict(ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0300681c-0645-4ed1-9909-6be98d021af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990963935852051\n",
      "0.9960978031158447\n",
      "0.9998791217803955\n",
      "0.999220609664917\n"
     ]
    }
   ],
   "source": [
    "print(senti_score(ds1))\n",
    "print(senti_score(ds2))\n",
    "print(senti_score(ds3))\n",
    "print(senti_score(ds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7ec0d-2f61-4e07-9216-5e3878a5a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in range(15):\n",
    "    print(sid.polarity_scores(df.iloc[each][\"text\"]))\n",
    "    print(senti_score(df.iloc[each][\"text\"]))\n",
    "    print(df.iloc[each][\"text\"])\n",
    "    print(str(each)+\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3583ee-7654-4250-94c5-775008733174",
   "metadata": {},
   "source": [
    "<h3>Stanza</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c663407b-7ab2-411f-b339-dc9b2feb5976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8141615ad46041e3ad77652a20afd8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 15:18:13 INFO: Downloading default packages for language: en (English)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317036775aee41c99ae271090f2d9a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.3.0/models/default.zip:   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 15:19:20 INFO: Finished downloading models and saved to /Users/tobias/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "#stanza.download(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2695e192-da7b-4855-8e9c-41f8859fa9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 21:55:00 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2022-04-03 21:55:00 INFO: Use device: cpu\n",
      "2022-04-03 21:55:00 INFO: Loading: tokenize\n",
      "2022-04-03 21:55:00 INFO: Loading: sentiment\n",
      "2022-04-03 21:55:01 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize,sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23544db9-9564-4c1b-b6fa-6d05a565981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"Tesla is a great company.\"\n",
    "s2 = \"Tesla is a good company.\"\n",
    "s3 = \"Tesla is just a company.\"\n",
    "s4 = \"Tesla is a bad company.\"\n",
    "s5 = \"Tesla might be a good company. It has some weak points and they are doing some bad studd. Overall I realy like the company. I think they are doing a great job and this is awesome.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cbbca98-37a9-4649-8b61-b7829f74f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I hat that they banned Mox Opal. Tesla is a great company.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2332b9-f7e3-4c2f-a7e1-1c972908e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [s1, s2, s3, s4, s5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6b6c452-669b-4909-8aab-f136bc2a7197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(i, sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66ee30ae-cb4f-4118-894e-a7819d7d6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f564bf4e-af38-4758-b2fe-c285096cc0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [2] 2.0\n",
      "1 [2] 2.0\n",
      "2 [1] 1.0\n",
      "3 [0] 0.0\n",
      "4 [2, 0, 1, 2] 1.25\n"
     ]
    }
   ],
   "source": [
    "for each in range(len(text_list)):\n",
    "    sentiment_value = []\n",
    "    doc = nlp(text_list[each])\n",
    "    for i, sentence in enumerate(doc.sentences):\n",
    "        sentiment_value.append(sentence.sentiment)\n",
    "    \n",
    "    print(each, sentiment_value,(sum(sentiment_value)/len(sentiment_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd01b506-4987-4133-bac5-14d76a2a0c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e916207e0fc40468ca86d1540cc8f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 18:21:19 INFO: Downloading default packages for language: de (German)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792da77fcb4e4ac198f99a1414084c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-de/resolve/v1.3.0/models/default.zip:   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 18:22:13 INFO: Finished downloading models and saved to /Users/tobias/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "#stanza.download(\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e460bb-da16-4690-a99a-8f915d152f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 21:56:27 WARNING: Language de package default expects mwt, which has been added\n",
      "2022-04-03 21:56:27 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| sentiment | sb10k   |\n",
      "=======================\n",
      "\n",
      "2022-04-03 21:56:27 INFO: Use device: cpu\n",
      "2022-04-03 21:56:27 INFO: Loading: tokenize\n",
      "2022-04-03 21:56:27 INFO: Loading: mwt\n",
      "2022-04-03 21:56:27 INFO: Loading: sentiment\n",
      "2022-04-03 21:56:27 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp_de = stanza.Pipeline(lang=\"de\", processors=\"tokenize,sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728532ff-4dae-451c-9367-de0f111d5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "de1 = \"Tesla ist eine tolle Firma\"\n",
    "de2 = \"Tesla ist die beste Firma\" \n",
    "de3 = \"Tesla ist eine scheiß Firma\"\n",
    "de4 = \"Tesla ist keine besonders tolle Firma\"\n",
    "de5 = \"Tesla ist eine ganz gute Firma. Sie hat ein paar schwächen und einige Aktionen sind scheiße. Dennoch ist es gut was sie erreicht hat. Sie hat etwas großartiges geschafft, was vorher noch keine andere Firma geschafft hat.\"\n",
    "de6 = \"Tesla ist die beste Firma auf der Welt. Sie ist so toll und absolut großartig!!!!\"\n",
    "de7 = \"Ich bin am tollsten\"\n",
    "de8 = \"Tesla ist die tollste Firma auf der Welt\"\n",
    "text_de_list = [de1, de2, de3, de4, de5, de6, de7, de8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0e2595-ba76-4162-ac94-1cfbc5dc2ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1] 1.0\n",
      "1 [1] 1.0\n",
      "2 [1] 1.0\n",
      "3 [1] 1.0\n",
      "4 [1, 0, 1, 1] 0.75\n",
      "5 [1, 2, 2] 1.6666666666666667\n",
      "6 [2] 2.0\n",
      "7 [1] 1.0\n"
     ]
    }
   ],
   "source": [
    "for each in range(len(text_de_list)):\n",
    "    sentiment_value = []\n",
    "    doc = nlp_de(text_de_list[each])\n",
    "    for i, sentence in enumerate(doc.sentences):\n",
    "        sentiment_value.append(sentence.sentiment)\n",
    "    \n",
    "    print(each, sentiment_value,(sum(sentiment_value)/len(sentiment_value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dfafc0-94ca-4433-a25c-e6094a267d09",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Load data from CSV file </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5caad5-e3fe-41ae-bd47-85521c26037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manager_de = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/Manager_DE/data.csv\", sep=\";\")\n",
    "df_wirecard_de = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/Wirecard_DE/data.csv\", sep=\";\")\n",
    "df_manager_en = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/Manager_EN/data.csv\", sep=\";\")\n",
    "df_wirecard_en = pd.read_csv(\"/Users/tobias/Dev/FOM/Master_Thesis/data/Wirecard_EN/data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8938619a-d597-457c-989d-72d454c4d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manager_DE: 14308\n",
      "Wirecard_DE: 165657\n",
      "Manager_EN: 17801\n",
      "Wirecard_EN: 203935\n"
     ]
    }
   ],
   "source": [
    "print(\"Manager_DE: \" + str(len(df_manager_de)))\n",
    "print(\"Wirecard_DE: \" + str(len(df_wirecard_de)))\n",
    "print(\"Manager_EN: \" + str(len(df_manager_en)))\n",
    "print(\"Wirecard_EN: \" + str(len(df_wirecard_en)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290de2a2-73d2-4a6f-92d4-6efe151e8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_de = len(df_manager_de) + len(df_wirecard_de)\n",
    "tweets_en = len(df_manager_en) + len(df_wirecard_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0193ad6-5971-4ff5-94ef-b279473ec51b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE: 179965\n",
      "EN: 221736\n"
     ]
    }
   ],
   "source": [
    "print(\"DE: \" + str(tweets_de) + \"\\nEN: \" + str(tweets_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1fe0bb-5c17-4037-a18e-3e56867e1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de = pd.concat([df_manager_de, df_wirecard_de], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98e57ee-b675-4c7f-8fbd-dc84273cbaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179965"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ed385b-a0c7-4618-a1af-7ac7ba2934a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_de = df_de.drop_duplicates(subset=[\"conversation_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70d4b0c-8c87-45f0-8f96-f4cb92581e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150686"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07eb3777-78da-403f-982c-241afdf50c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de = df_de.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39240307-dc80-4872-92e2-809e250fbe97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversation_id                                  944209488080527360\n",
       "author_id                                                2942451119\n",
       "created_at                                2018-03-12 18:02:14+00:00\n",
       "tweet_id                                         973257873844310016\n",
       "lang                                                             de\n",
       "retweet_count                                                     0\n",
       "reply_count                                                       0\n",
       "like_count                                                        0\n",
       "quote_count                                                       0\n",
       "source                                          Twitter for Android\n",
       "tweet_type                                           ['replied_to']\n",
       "referenced_tweet_id                          ['944209488080527360']\n",
       "text                   @_MarkusBraun Jetzt einen schönen Wurstsalat\n",
       "Name: 71, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_de.iloc[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb8428d8-6ca5-4293-9bc0-51158277f96b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:16:36.062423\n",
      "2022-03-26 10:16:37.889832\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "\n",
    "for each in range(len(df_de)):\n",
    "    #print(each) 17\n",
    "    df_de.at[each,\"tweet_type\"] = re.findall(r\"\\w+\", df_de.at[each,\"tweet_type\"])\n",
    "    \n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c6358c-6c8c-4be5-8ffb-7c6a62552089",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversation_id                                  944209488080527360\n",
       "author_id                                                2942451119\n",
       "created_at                                2018-03-12 18:02:14+00:00\n",
       "tweet_id                                         973257873844310016\n",
       "lang                                                             de\n",
       "retweet_count                                                     0\n",
       "reply_count                                                       0\n",
       "like_count                                                        0\n",
       "quote_count                                                       0\n",
       "source                                          Twitter for Android\n",
       "tweet_type                                             [replied_to]\n",
       "referenced_tweet_id                          ['944209488080527360']\n",
       "text                   @_MarkusBraun Jetzt einen schönen Wurstsalat\n",
       "Name: 71, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_de.iloc[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4c1eb-e5ef-48fe-a89e-a55aeef07cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "745f7f7d-466b-437c-9a0f-d6207ea0156c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>referenced_tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703311366262800384</td>\n",
       "      <td>1392131804</td>\n",
       "      <td>2016-02-26 20:11:11+00:00</td>\n",
       "      <td>703311366262800384</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>#Wirecard-Chef Markus Braun pumpt irrwitzige S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702405572012974080</td>\n",
       "      <td>1053723204</td>\n",
       "      <td>2016-02-24 08:11:53+00:00</td>\n",
       "      <td>702405572012974080</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>Jetzt günstig einsammeln und später absahnen? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>701784983829143553</td>\n",
       "      <td>554491983</td>\n",
       "      <td>2016-02-22 15:05:53+00:00</td>\n",
       "      <td>701784983829143553</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>Morgen startet die neue Reihe R²-JazzCube! Vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701446667170615296</td>\n",
       "      <td>3365669884</td>\n",
       "      <td>2016-02-21 16:41:32+00:00</td>\n",
       "      <td>701446667170615296</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>die Y-Achse des  #prusai3 nimmt Formen an :-) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700597812556386304</td>\n",
       "      <td>4858383167</td>\n",
       "      <td>2016-02-19 08:28:29+00:00</td>\n",
       "      <td>700597812556386304</td>\n",
       "      <td>de</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>[retweeted]</td>\n",
       "      <td>['700578193334411264']</td>\n",
       "      <td>RT @aktionaer: #Wirecard: Was führt der Vorsta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>945973335258787840</td>\n",
       "      <td>917052505430863873</td>\n",
       "      <td>2018-03-14 08:36:34+00:00</td>\n",
       "      <td>973840298274164738</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>[replied_to]</td>\n",
       "      <td>['945973335258787840']</td>\n",
       "      <td>@_MarkusBraun Man sollte sich überlegen, einen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>944209488080527360</td>\n",
       "      <td>2942451119</td>\n",
       "      <td>2018-03-12 18:02:14+00:00</td>\n",
       "      <td>973257873844310016</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>[replied_to]</td>\n",
       "      <td>['944209488080527360']</td>\n",
       "      <td>@_MarkusBraun Jetzt einen schönen Wurstsalat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>973195874888290304</td>\n",
       "      <td>751899999752036354</td>\n",
       "      <td>2018-03-12 14:16:41+00:00</td>\n",
       "      <td>973201112219217921</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>[replied_to]</td>\n",
       "      <td>['973195874888290304']</td>\n",
       "      <td>@Ademm66Mr @wirecard @bankenverband @_MarkusBr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>984792434533191680</td>\n",
       "      <td>17771831</td>\n",
       "      <td>2018-04-13 13:56:27+00:00</td>\n",
       "      <td>984792434533191680</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>RT @BlarryOfficial: @bvbflo09 @threalNox @seba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>984778759629885440</td>\n",
       "      <td>2482271094</td>\n",
       "      <td>2018-04-13 13:53:24+00:00</td>\n",
       "      <td>984791666069590016</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>[replied_to]</td>\n",
       "      <td>['984779935964377091']</td>\n",
       "      <td>@bvbflo09 @threalNox @sebastiankehl @FCBayern ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       conversation_id           author_id                 created_at  \\\n",
       "0   703311366262800384          1392131804  2016-02-26 20:11:11+00:00   \n",
       "1   702405572012974080          1053723204  2016-02-24 08:11:53+00:00   \n",
       "2   701784983829143553           554491983  2016-02-22 15:05:53+00:00   \n",
       "3   701446667170615296          3365669884  2016-02-21 16:41:32+00:00   \n",
       "4   700597812556386304          4858383167  2016-02-19 08:28:29+00:00   \n",
       "..                 ...                 ...                        ...   \n",
       "70  945973335258787840  917052505430863873  2018-03-14 08:36:34+00:00   \n",
       "71  944209488080527360          2942451119  2018-03-12 18:02:14+00:00   \n",
       "72  973195874888290304  751899999752036354  2018-03-12 14:16:41+00:00   \n",
       "73  984792434533191680            17771831  2018-04-13 13:56:27+00:00   \n",
       "74  984778759629885440          2482271094  2018-04-13 13:53:24+00:00   \n",
       "\n",
       "              tweet_id lang  retweet_count  reply_count  like_count  \\\n",
       "0   703311366262800384   de              0            0           2   \n",
       "1   702405572012974080   de              0            0           0   \n",
       "2   701784983829143553   de              0            0           0   \n",
       "3   701446667170615296   de              0            0           1   \n",
       "4   700597812556386304   de              2            0           0   \n",
       "..                 ...  ...            ...          ...         ...   \n",
       "70  973840298274164738   de              0            0           0   \n",
       "71  973257873844310016   de              0            0           0   \n",
       "72  973201112219217921   de              0            1           0   \n",
       "73  984792434533191680   de              0            0           0   \n",
       "74  984791666069590016   de              0            1           1   \n",
       "\n",
       "    quote_count               source    tweet_type     referenced_tweet_id  \\\n",
       "0             0   Twitter Web Client        [None]                  [None]   \n",
       "1             0   Twitter Web Client        [None]                  [None]   \n",
       "2             0             Facebook        [None]                  [None]   \n",
       "3             0   Twitter Web Client        [None]                  [None]   \n",
       "4             0   Twitter for iPhone   [retweeted]  ['700578193334411264']   \n",
       "..          ...                  ...           ...                     ...   \n",
       "70            0  Twitter for Android  [replied_to]  ['945973335258787840']   \n",
       "71            0  Twitter for Android  [replied_to]  ['944209488080527360']   \n",
       "72            0   Twitter Web Client  [replied_to]  ['973195874888290304']   \n",
       "73            0                IFTTT        [None]                  [None]   \n",
       "74            0   Twitter Web Client  [replied_to]  ['984779935964377091']   \n",
       "\n",
       "                                                 text  \n",
       "0   #Wirecard-Chef Markus Braun pumpt irrwitzige S...  \n",
       "1   Jetzt günstig einsammeln und später absahnen? ...  \n",
       "2   Morgen startet die neue Reihe R²-JazzCube! Vol...  \n",
       "3   die Y-Achse des  #prusai3 nimmt Formen an :-) ...  \n",
       "4   RT @aktionaer: #Wirecard: Was führt der Vorsta...  \n",
       "..                                                ...  \n",
       "70  @_MarkusBraun Man sollte sich überlegen, einen...  \n",
       "71       @_MarkusBraun Jetzt einen schönen Wurstsalat  \n",
       "72  @Ademm66Mr @wirecard @bankenverband @_MarkusBr...  \n",
       "73  RT @BlarryOfficial: @bvbflo09 @threalNox @seba...  \n",
       "74  @bvbflo09 @threalNox @sebastiankehl @FCBayern ...  \n",
       "\n",
       "[75 rows x 13 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_de.head(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e113b-a6fa-4932-915e-a29085c40e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534ac86-2b5e-4f5e-8759-191b305158ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed1dcf-db57-4559-9b69-a29564bc191e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2a719-ef3b-4b2e-af41-daf1637e5c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf77bce-0158-4e3f-b43c-8b4c6dffef3b",
   "metadata": {},
   "source": [
    "<h2>Preprocessing Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a34c0727-a471-455f-9e26-138bca91e2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for each in range(len(df_manager_de)):\n",
    "    df_manager_de.at[each,\"tweet_type\"] = re.findall(r\"\\w+\", df_manager_de.at[each, \"tweet_type\"])\n",
    "    #print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61753e90-0d36-4c27-9cdd-057bbf4d40eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "[1854, 3491, 4568, 5346, 5481, 5866, 5910, 5911, 5912, 5934, 5935, 5936, 5937, 5938, 5969, 5972, 5973, 5975, 5976, 5998, 5999, 6001, 6002, 6003, 6004, 6005, 6006, 6018, 6020, 6029, 6030, 6031, 6032, 6033, 6034, 6035, 6041, 6051, 6052, 6053, 6054, 6055, 6056, 6057, 6058, 6059, 6060, 6061, 6062, 6063, 6064, 6065, 6066, 6079, 6080, 6081, 6082, 6083, 6084, 6085, 6086, 6087, 6091, 6095, 6096, 6097, 6099, 6100, 6101, 6102, 6103, 6104, 6105, 6106, 6107, 6108, 6109, 6116, 6118, 6119, 6124, 6125, 6127, 6128, 6130, 6131, 6147, 6150, 6153, 6155, 6156, 6158, 6160, 6162, 6172, 6173, 6174, 6175, 6176, 6178, 6179, 6181, 6182, 6184, 6186, 6189, 6190, 6191, 6194, 6196, 6197, 6198, 6199, 6200, 6204, 6206, 6207, 6208, 6210, 6212, 6213, 6340, 9629, 9675, 16145, 18216, 18939, 29871, 38798, 39281, 44789, 46703, 59083, 62656, 63405, 65430, 67090, 70141, 70196, 70201, 70574, 71364, 76438, 76439, 78110, 78456, 79410, 80123, 80476, 80711, 81357, 81958, 87878, 91141, 91548, 92952, 95761, 96130, 97522, 97894, 98311, 98672, 99450, 99848, 101149, 105535, 106182, 106393, 106824, 107940, 108462, 108494, 108543, 108548, 108549, 108585, 116667, 119751, 121150, 128459, 128785, 133335, 133740, 133975, 135447, 135652, 137983, 145595, 147156]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "multiple_tweet_types = []\n",
    "for each in range(len(df_de)):\n",
    "    if len(df_de[\"tweet_type\"][each]) > 1:\n",
    "        multiple_tweet_types.append(each)\n",
    "        counter += 1\n",
    "print(counter)\n",
    "print(multiple_tweet_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d5830e4-6959-411e-8cd1-a5548d520ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = df_de.iloc[71][\"tweet_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "141f97c4-108e-4f40-b0cf-02f09f046fc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (150686,), (1,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_de[\u001b[43mdf_de\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtweet_list\u001b[49m]\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/pandas/core/series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5620\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 5623\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/Dev/FOM/Master_Thesis/master_thesis_3.9.10/.venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:260\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# TODO: make this treatment consistent across ops and classes.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m#  We are not catching all listlikes here (e.g. frozenset, tuple)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m#  The ambiguous case is object-dtype.  See GH#27803\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lvalues) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rvalues):\n\u001b[0;32m--> 260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    262\u001b[0m         )\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    265\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    267\u001b[0m ):\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(lvalues, rvalues)\n",
      "\u001b[0;31mValueError\u001b[0m: ('Lengths must match to compare', (150686,), (1,))"
     ]
    }
   ],
   "source": [
    "df_de[df_de[\"tweet_type\"] == tweet_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db549348-b466-4fb9-914e-76ca495d6c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_3.9.10",
   "language": "python",
   "name": "master_thesis_3.9.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
